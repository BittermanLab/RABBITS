{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "# load datasets from huggingface hub\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Features, Value, ClassLabel, Sequence\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "#  set max display width too view full text\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 811/811 [00:00<00:00, 1.14MB/s]\n",
      "Downloading data: 100%|██████████| 1.81M/1.81M [00:00<00:00, 5.95MB/s]\n",
      "Downloading data: 100%|██████████| 227k/227k [00:00<00:00, 1.34MB/s]\n",
      "Downloading data: 100%|██████████| 215k/215k [00:00<00:00, 920kB/s]\n",
      "Generating train split: 100%|██████████| 3310/3310 [00:00<00:00, 70435.64 examples/s]\n",
      "Generating validation split: 100%|██████████| 399/399 [00:00<00:00, 124416.57 examples/s]\n",
      "Generating test split: 100%|██████████| 378/378 [00:00<00:00, 141204.75 examples/s]\n",
      "Downloading readme: 100%|██████████| 811/811 [00:00<00:00, 2.18MB/s]\n",
      "Downloading data: 100%|██████████| 1.80M/1.80M [00:00<00:00, 8.84MB/s]\n",
      "Downloading data: 100%|██████████| 226k/226k [00:00<00:00, 1.25MB/s]\n",
      "Downloading data: 100%|██████████| 214k/214k [00:00<00:00, 1.13MB/s]\n",
      "Generating train split: 100%|██████████| 3310/3310 [00:00<00:00, 198025.14 examples/s]\n",
      "Generating validation split: 100%|██████████| 399/399 [00:00<00:00, 109674.77 examples/s]\n",
      "Generating test split: 100%|██████████| 378/378 [00:00<00:00, 108369.58 examples/s]\n",
      "Downloading readme: 100%|██████████| 1.01k/1.01k [00:00<00:00, 2.09MB/s]\n",
      "Downloading data: 100%|██████████| 8.65M/8.65M [00:00<00:00, 29.8MB/s]\n",
      "Downloading data: 100%|██████████| 147k/147k [00:00<00:00, 1.05MB/s]\n",
      "Downloading data: 100%|██████████| 77.2k/77.2k [00:00<00:00, 406kB/s]\n",
      "Generating train split: 100%|██████████| 19044/19044 [00:00<00:00, 417669.28 examples/s]\n",
      "Generating validation split: 100%|██████████| 348/348 [00:00<00:00, 156058.78 examples/s]\n",
      "Generating test split: 100%|██████████| 457/457 [00:00<00:00, 224239.23 examples/s]\n",
      "Downloading readme: 100%|██████████| 1.01k/1.01k [00:00<00:00, 7.61MB/s]\n",
      "Downloading data: 100%|██████████| 8.62M/8.62M [00:00<00:00, 30.7MB/s]\n",
      "Downloading data: 100%|██████████| 147k/147k [00:00<00:00, 795kB/s]\n",
      "Downloading data: 100%|██████████| 75.9k/75.9k [00:00<00:00, 386kB/s]\n",
      "Generating train split: 100%|██████████| 19044/19044 [00:00<00:00, 286178.14 examples/s]\n",
      "Generating validation split: 100%|██████████| 348/348 [00:00<00:00, 142152.10 examples/s]\n",
      "Generating test split: 100%|██████████| 457/457 [00:00<00:00, 199127.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_filtered_medqa shape:  (378, 10)\n",
      "g2b_medqa shape:  (378, 10)\n",
      "orig_filtered_medmcqa shape:  (457, 13)\n",
      "g2b_medmcqa shape:  (457, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load orig_filtered and g2b versions of GBaker/MedQA-USMLE-4-options-hf\n",
    "orig_filtered_medqa = load_dataset(\n",
    "    \"AIM-Harvard/gbaker_medqa_usmle_4_options_hf_original\", split=\"test\"\n",
    ")\n",
    "g2b_medqa = load_dataset(\n",
    "    \"AIM-Harvard/gbaker_medqa_usmle_4_options_hf_generic_to_brand\", split=\"test\"\n",
    ")\n",
    "\n",
    "orig_filtered_medmcqa = load_dataset(\"AIM-Harvard/medmcqa_original\", split=\"test\")\n",
    "g2b_medmcqa = load_dataset(\"AIM-Harvard/medmcqa_generic_to_brand\", split=\"test\")\n",
    "\n",
    "# convert to pandas\n",
    "orig_filtered_medqa = orig_filtered_medqa.to_pandas()\n",
    "g2b_medqa = g2b_medqa.to_pandas()\n",
    "\n",
    "orig_filtered_medmcqa = orig_filtered_medmcqa.to_pandas()\n",
    "g2b_medmcqa = g2b_medmcqa.to_pandas()\n",
    "\n",
    "# print shape\n",
    "print(\"orig_filtered_medqa shape: \", orig_filtered_medqa.shape)\n",
    "print(\"g2b_medqa shape: \", g2b_medqa.shape)\n",
    "\n",
    "print(\"orig_filtered_medmcqa shape: \", orig_filtered_medmcqa.shape)\n",
    "print(\"g2b_medmcqa shape: \", g2b_medmcqa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_orig</th>\n",
       "      <th>opa_orig</th>\n",
       "      <th>opb_orig</th>\n",
       "      <th>opc_orig</th>\n",
       "      <th>opd_orig</th>\n",
       "      <th>cop_orig</th>\n",
       "      <th>choice_type_orig</th>\n",
       "      <th>exp_orig</th>\n",
       "      <th>subject_name_orig</th>\n",
       "      <th>topic_name_orig</th>\n",
       "      <th>found_keywords_orig</th>\n",
       "      <th>local_id_orig</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>question_g2b</th>\n",
       "      <th>opa_g2b</th>\n",
       "      <th>opb_g2b</th>\n",
       "      <th>opc_g2b</th>\n",
       "      <th>opd_g2b</th>\n",
       "      <th>cop_g2b</th>\n",
       "      <th>choice_type_g2b</th>\n",
       "      <th>exp_g2b</th>\n",
       "      <th>subject_name_g2b</th>\n",
       "      <th>topic_name_g2b</th>\n",
       "      <th>found_keywords_g2b</th>\n",
       "      <th>local_id_g2b</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>keep/drop</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006acfff-dc8f-4bb5-97b2-e26144c56483</td>\n",
       "      <td>PGE1 analogue is ?</td>\n",
       "      <td>Carboprost</td>\n",
       "      <td>Alprostadil</td>\n",
       "      <td>Epoprostenol</td>\n",
       "      <td>Dinoprostone</td>\n",
       "      <td>-1</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pharmacology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['carboprost' 'dinoprostone' 'alprostadil' 'epoprostenol']</td>\n",
       "      <td>4101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGE1 analogue is ?</td>\n",
       "      <td>hemabate</td>\n",
       "      <td>caverject</td>\n",
       "      <td>flolan</td>\n",
       "      <td>cervidil</td>\n",
       "      <td>-1</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pharmacology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['carboprost' 'dinoprostone' 'alprostadil' 'epoprostenol']</td>\n",
       "      <td>4101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>024f96d1-8881-4b52-a7f9-58e5b194a0fa</td>\n",
       "      <td>Which of the following cephalosporin is active against Pseudomonas aeruginosa:</td>\n",
       "      <td>Ceftriaxone</td>\n",
       "      <td>Cephalothin</td>\n",
       "      <td>Ceftazidime</td>\n",
       "      <td>Cefotaxime</td>\n",
       "      <td>-1</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cefotaxime' 'ceftazidime' 'cephalothin' 'ceftriaxone']</td>\n",
       "      <td>1162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which of the following cephalosporin is active against Pseudomonas aeruginosa:</td>\n",
       "      <td>rocephin</td>\n",
       "      <td>keflin</td>\n",
       "      <td>fortaz</td>\n",
       "      <td>claforan</td>\n",
       "      <td>-1</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cefotaxime' 'ceftazidime' 'cephalothin' 'ceftriaxone']</td>\n",
       "      <td>1162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  006acfff-dc8f-4bb5-97b2-e26144c56483   \n",
       "1  024f96d1-8881-4b52-a7f9-58e5b194a0fa   \n",
       "\n",
       "                                                                    question_orig  \\\n",
       "0                                                              PGE1 analogue is ?   \n",
       "1  Which of the following cephalosporin is active against Pseudomonas aeruginosa:   \n",
       "\n",
       "      opa_orig     opb_orig      opc_orig      opd_orig cop_orig  \\\n",
       "0   Carboprost  Alprostadil  Epoprostenol  Dinoprostone       -1   \n",
       "1  Ceftriaxone  Cephalothin   Ceftazidime    Cefotaxime       -1   \n",
       "\n",
       "  choice_type_orig  exp_orig subject_name_orig  topic_name_orig  \\\n",
       "0           single       NaN      Pharmacology              NaN   \n",
       "1           single       NaN           Unknown              NaN   \n",
       "\n",
       "                                          found_keywords_orig  local_id_orig  \\\n",
       "0  ['carboprost' 'dinoprostone' 'alprostadil' 'epoprostenol']           4101   \n",
       "1    ['cefotaxime' 'ceftazidime' 'cephalothin' 'ceftriaxone']           1162   \n",
       "\n",
       "   Unnamed: 13  \\\n",
       "0          NaN   \n",
       "1          NaN   \n",
       "\n",
       "                                                                     question_g2b  \\\n",
       "0                                                              PGE1 analogue is ?   \n",
       "1  Which of the following cephalosporin is active against Pseudomonas aeruginosa:   \n",
       "\n",
       "    opa_g2b    opb_g2b opc_g2b   opd_g2b  cop_g2b choice_type_g2b  exp_g2b  \\\n",
       "0  hemabate  caverject  flolan  cervidil       -1          single      NaN   \n",
       "1  rocephin     keflin  fortaz  claforan       -1          single      NaN   \n",
       "\n",
       "  subject_name_g2b  topic_name_g2b  \\\n",
       "0     Pharmacology             NaN   \n",
       "1          Unknown             NaN   \n",
       "\n",
       "                                           found_keywords_g2b  local_id_g2b  \\\n",
       "0  ['carboprost' 'dinoprostone' 'alprostadil' 'epoprostenol']          4101   \n",
       "1    ['cefotaxime' 'ceftazidime' 'cephalothin' 'ceftriaxone']          1162   \n",
       "\n",
       "   Unnamed: 26 keep/drop comments  \n",
       "0          NaN      keep      NaN  \n",
       "1          NaN      keep      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre_filter_datasets/eval_csvs/annotated_medmcqa_new.csv\n",
    "annotated_medmcqa_new = pd.read_csv(\n",
    "    \"../pre_filter_datasets/eval_csvs/annotated_medmcqa_new.csv\"\n",
    ")\n",
    "\n",
    "annotated_medqa_new = pd.read_csv(\n",
    "    \"../pre_filter_datasets/eval_csvs/annotated_medqa_new.csv\"\n",
    ")\n",
    "\n",
    "annotated_medmcqa_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows to filter in medmcqa: 82\n",
      "Number of rows to filter in medqa: 63\n"
     ]
    }
   ],
   "source": [
    "# get list of ids to filter (where penultimate column is not \"keep\")\n",
    "# make the col is string\n",
    "annotated_medmcqa_new.iloc[:, -2] = annotated_medmcqa_new.iloc[:, -2].astype(str)\n",
    "\n",
    "rows_to_filter = annotated_medmcqa_new[\n",
    "    annotated_medmcqa_new.iloc[:, -2] != \"keep\"\n",
    "].id.tolist()\n",
    "\n",
    "# same for medqa\n",
    "annotated_medqa_new.iloc[:, -2] = annotated_medqa_new.iloc[:, -2].astype(str)\n",
    "\n",
    "rows_to_filter_medqa = annotated_medqa_new[\n",
    "    annotated_medqa_new.iloc[:, -2] != \"keep\"\n",
    "].id.tolist()\n",
    "\n",
    "print(f\"Number of rows to filter in medmcqa: {len(rows_to_filter)}\")\n",
    "print(f\"Number of rows to filter in medqa: {len(rows_to_filter_medqa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in filtered_orig_filtered_medmcqa: 457\n",
      "Number of rows in filtered_g2b_medmcqa: 457\n",
      "Number of rows in filtered_orig_filtered_medqa: 378\n",
      "Number of rows in filtered_g2b_medqa: 378\n",
      "Difference in rows in filtered_orig_filtered_medmcqa: 82\n",
      "Difference in rows in filtered_g2b_medmcqa: 82\n",
      "Difference in rows in filtered_orig_filtered_medqa: 63\n",
      "Difference in rows in filtered_g2b_medqa: 63\n"
     ]
    }
   ],
   "source": [
    "# get the ids of the rows to filter in annotated_medmcqa_new\n",
    "medmcqa_rows_to_filter = annotated_medmcqa_new[\n",
    "    annotated_medmcqa_new.iloc[:, -2] != \"keep\"\n",
    "].id.tolist()\n",
    "\n",
    "\n",
    "# get the ids of the rows to filter in annotated_medqa_new\n",
    "medqa_rows_to_filter = annotated_medqa_new[\n",
    "    annotated_medqa_new.iloc[:, -2] != \"keep\"\n",
    "].id.tolist()\n",
    "\n",
    "# filter out the rows from the pandas hf datasets in orig and g2b\n",
    "filtered_orig_filtered_medmcqa = orig_filtered_medmcqa[\n",
    "    ~orig_filtered_medmcqa.id.isin(medmcqa_rows_to_filter)\n",
    "]\n",
    "filtered_g2b_medmcqa = g2b_medmcqa[~g2b_medmcqa.id.isin(medmcqa_rows_to_filter)]\n",
    "\n",
    "filtered_orig_filtered_medqa = orig_filtered_medqa[\n",
    "    ~orig_filtered_medqa.id.isin(medqa_rows_to_filter)\n",
    "]\n",
    "filtered_g2b_medqa = g2b_medqa[~g2b_medqa.id.isin(medqa_rows_to_filter)]\n",
    "\n",
    "# check rows and difference\n",
    "print(\n",
    "    f\"Number of rows in filtered_orig_filtered_medmcqa: {len(filtered_orig_filtered_medmcqa)}\"\n",
    ")\n",
    "print(f\"Number of rows in filtered_g2b_medmcqa: {len(filtered_g2b_medmcqa)}\")\n",
    "print(\n",
    "    f\"Number of rows in filtered_orig_filtered_medqa: {len(filtered_orig_filtered_medqa)}\"\n",
    ")\n",
    "print(f\"Number of rows in filtered_g2b_medqa: {len(filtered_g2b_medqa)}\")\n",
    "print(\n",
    "    f\"Difference in rows in filtered_orig_filtered_medmcqa: {len(orig_filtered_medmcqa) - len(filtered_orig_filtered_medmcqa)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Difference in rows in filtered_g2b_medmcqa: {len(g2b_medmcqa) - len(filtered_g2b_medmcqa)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Difference in rows in filtered_orig_filtered_medqa: {len(orig_filtered_medqa) - len(filtered_orig_filtered_medqa)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Difference in rows in filtered_g2b_medqa: {len(g2b_medqa) - len(filtered_g2b_medqa)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset: medmcqa\n",
      "Split: test\n",
      "Contains 1617 rows.\n",
      "539 transformations.\n",
      "\n",
      "Merged Dataset: GBaker/MedQA-USMLE-4-options-hf\n",
      "Split: test\n",
      "Contains 1323 rows.\n",
      "441 transformations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>n_questions</th>\n",
       "      <th>keywords</th>\n",
       "      <th>total_keyword_length</th>\n",
       "      <th>brand_keywords_count</th>\n",
       "      <th>generic_keywords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>test</td>\n",
       "      <td>539</td>\n",
       "      <td>[danazol, levofloxacin, moxifloxacin, ciprofloxacin, ofloxacin, pegvisomant, fulvestrant, vigabatrin, cabergoline, ziprasidone, aripiprazole, clozapine, quetiapine, pentazocine, methadone, tetracycline, dapsone, methotrexate, amikacin, ampicillin, phenytoin, ipratropium, oxytocin, glucagon, epinephrine, glutaraldehyde, nystatin, griseofulvin, trimipramine, doxepin, amitriptyline, desipramine, glucagon, ritonavir, indinavir, ciclesonide, digoxin, acetazolamide, flutamide, mifepristone, metyrapone, ketamine, propofol, glucagon, paba, docetaxel, paclitaxel, papaverine, atropine, nevirapine, methotrexate, sulfasalazine, chloroquine, ambenonium, edrophonium, eptifibatide, abciximab, clopidogrel, tirofiban, chlorpropamide, tolbutamide, nefazodone, furosemide, warfarin, oxytocin, metyrapone, oxytocin, theophylline, ciprofloxacin, procarbazine, topotecan, repaglinide, glucagon, dibucaine, piroxicam, sulindac, chlorhexidine, octreotide, bisoprolol, acebutolol, esmolol, pindolol, erythromycin, tetracycline, procainamide, metoclopramide, dapsone, cycloserine, hydralazine, penicillamine, doripenem, carbidopa, bromocriptine, levodopa, oseltamivir, cisplatin, epinephrine, glucagon, nevirapine, saquinavir, ...]</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBaker/MedQA-USMLE-4-options-hf</td>\n",
       "      <td>test</td>\n",
       "      <td>441</td>\n",
       "      <td>[lamivudine, prednisone, cisplatin, metformin, lamivudine, dolutegravir, ritonavir, emtricitabine, efavirenz, metformin, fenofibrate, lisinopril, simvastatin, hydrochlorothiazide, hydrochlorothiazide, ibuprofen, ramipril, donepezil, metformin, acetazolamide, metformin, metoprolol, verapamil, enalapril, chloroquine, salbutamol, diphenhydramine, metformin, ibuprofen, naltrexone, fomepizole, metformin, oseltamivir, lisinopril, amlodipine, hydrochlorothiazide, oxybutynin, bethanechol, metoclopramide, galantamine, metronidazole, morphine, atropine, scopolamine, thyroxine, phentolamine, prazosin, octreotide, lisinopril, atenolol, morphine, cefotaxime, lisinopril, ceftriaxone, atorvastatin, metformin, hydrochlorothiazide, ibuprofen, lisinopril, ibuprofen, naltrexone, ipratropium, fexofenadine, itraconazole, doxycycline, griseofulvin, oxymetazoline, morphine, sildenafil, metoprolol, cilostazol, diphenhydramine, vasopressin, pantoprazole, bupropion, simvastatin, citalopram, levofloxacin, salmeterol, prednisone, metformin, oxycodone, spironolactone, hydrochlorothiazide, metformin, ibuprofen, hydrochlorothiazide, propranolol, azathioprine, cyclosporine, prednisone, enalapril, phenoxybenzamine, atenolol, propranolol, epinephrine, thyroxine, indomethacin, ampicillin, mepolizumab, ...]</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset split  n_questions  \\\n",
       "0                          medmcqa  test          539   \n",
       "1  GBaker/MedQA-USMLE-4-options-hf  test          441   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       keywords  \\\n",
       "0                                                                               [danazol, levofloxacin, moxifloxacin, ciprofloxacin, ofloxacin, pegvisomant, fulvestrant, vigabatrin, cabergoline, ziprasidone, aripiprazole, clozapine, quetiapine, pentazocine, methadone, tetracycline, dapsone, methotrexate, amikacin, ampicillin, phenytoin, ipratropium, oxytocin, glucagon, epinephrine, glutaraldehyde, nystatin, griseofulvin, trimipramine, doxepin, amitriptyline, desipramine, glucagon, ritonavir, indinavir, ciclesonide, digoxin, acetazolamide, flutamide, mifepristone, metyrapone, ketamine, propofol, glucagon, paba, docetaxel, paclitaxel, papaverine, atropine, nevirapine, methotrexate, sulfasalazine, chloroquine, ambenonium, edrophonium, eptifibatide, abciximab, clopidogrel, tirofiban, chlorpropamide, tolbutamide, nefazodone, furosemide, warfarin, oxytocin, metyrapone, oxytocin, theophylline, ciprofloxacin, procarbazine, topotecan, repaglinide, glucagon, dibucaine, piroxicam, sulindac, chlorhexidine, octreotide, bisoprolol, acebutolol, esmolol, pindolol, erythromycin, tetracycline, procainamide, metoclopramide, dapsone, cycloserine, hydralazine, penicillamine, doripenem, carbidopa, bromocriptine, levodopa, oseltamivir, cisplatin, epinephrine, glucagon, nevirapine, saquinavir, ...]   \n",
       "1  [lamivudine, prednisone, cisplatin, metformin, lamivudine, dolutegravir, ritonavir, emtricitabine, efavirenz, metformin, fenofibrate, lisinopril, simvastatin, hydrochlorothiazide, hydrochlorothiazide, ibuprofen, ramipril, donepezil, metformin, acetazolamide, metformin, metoprolol, verapamil, enalapril, chloroquine, salbutamol, diphenhydramine, metformin, ibuprofen, naltrexone, fomepizole, metformin, oseltamivir, lisinopril, amlodipine, hydrochlorothiazide, oxybutynin, bethanechol, metoclopramide, galantamine, metronidazole, morphine, atropine, scopolamine, thyroxine, phentolamine, prazosin, octreotide, lisinopril, atenolol, morphine, cefotaxime, lisinopril, ceftriaxone, atorvastatin, metformin, hydrochlorothiazide, ibuprofen, lisinopril, ibuprofen, naltrexone, ipratropium, fexofenadine, itraconazole, doxycycline, griseofulvin, oxymetazoline, morphine, sildenafil, metoprolol, cilostazol, diphenhydramine, vasopressin, pantoprazole, bupropion, simvastatin, citalopram, levofloxacin, salmeterol, prednisone, metformin, oxycodone, spironolactone, hydrochlorothiazide, metformin, ibuprofen, hydrochlorothiazide, propranolol, azathioprine, cyclosporine, prednisone, enalapril, phenoxybenzamine, atenolol, propranolol, epinephrine, thyroxine, indomethacin, ampicillin, mepolizumab, ...]   \n",
       "\n",
       "   total_keyword_length  brand_keywords_count  generic_keywords_count  \n",
       "0                  1002                     0                    1000  \n",
       "1                   950                     0                     947  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of brand keywords and generic keywords\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def load_brand_generic_maps(brand_to_generic_path, generic_to_brand_path):\n",
    "    brand_to_generic_df = pd.read_csv(brand_to_generic_path)\n",
    "    generic_to_brand_df = pd.read_csv(generic_to_brand_path)\n",
    "\n",
    "    brand_keywords = set(brand_to_generic_df[\"brand\"])\n",
    "    generic_keywords = set(generic_to_brand_df[\"generic\"])\n",
    "\n",
    "    return brand_keywords, generic_keywords\n",
    "\n",
    "\n",
    "def count_keywords(merged_datasets, split, brand_keywords, generic_keywords):\n",
    "    results = []\n",
    "    for dataset_name, df in merged_datasets.items():\n",
    "        if \"found_keywords\" in df.columns:\n",
    "            # Flatten the list of keywords\n",
    "            all_keywords = [\n",
    "                keyword\n",
    "                for sublist in df[\"found_keywords\"].dropna()\n",
    "                for keyword in sublist\n",
    "            ]\n",
    "\n",
    "            # Count total number of words (keywords)\n",
    "            total_keyword_length = len(all_keywords)\n",
    "\n",
    "            # Count brand and generic keywords\n",
    "            brand_keyword_count = sum(\n",
    "                1 for keyword in all_keywords if keyword in brand_keywords\n",
    "            )\n",
    "            generic_keyword_count = sum(\n",
    "                1 for keyword in all_keywords if keyword in generic_keywords\n",
    "            )\n",
    "\n",
    "            # divide by 3 to get the number of questions\n",
    "            total_keyword_length = total_keyword_length // 3\n",
    "            brand_keyword_count = brand_keyword_count // 3\n",
    "            generic_keyword_count = generic_keyword_count // 3\n",
    "\n",
    "            # get n questions\n",
    "            n = len(df) // 3\n",
    "\n",
    "            # Collect the results\n",
    "            results.append(\n",
    "                {\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"split\": split,\n",
    "                    \"n_questions\": n,\n",
    "                    \"keywords\": all_keywords,\n",
    "                    \"total_keyword_length\": total_keyword_length,\n",
    "                    \"brand_keywords_count\": brand_keyword_count,\n",
    "                    \"generic_keywords_count\": generic_keyword_count,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No 'found_keywords' column in {dataset_name}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Load brand and generic keyword maps\n",
    "brand_to_generic_path = \"../RxNorm_eval/filtered_keywords.csv\"\n",
    "generic_to_brand_path = \"../RxNorm_eval/filtered_keywords.csv\"\n",
    "brand_keywords, generic_keywords = load_brand_generic_maps(\n",
    "    brand_to_generic_path, generic_to_brand_path\n",
    ")\n",
    "\n",
    "# Assuming merge_all_datasets function is already defined\n",
    "merged_datasets = merge_all_datasets(pre_filtered_df_dir, split)\n",
    "\n",
    "# Count keywords and get the result as a DataFrame\n",
    "keywords_df = count_keywords(merged_datasets, split, brand_keywords, generic_keywords)\n",
    "\n",
    "# save the keywords_df\n",
    "keywords_df.to_csv(f\"../RxNorm_eval/keywords_count_{split}.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of keywords that appeared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset: medmcqa\n",
      "Split: test\n",
      "Contains 1617 rows.\n",
      "539 transformations.\n",
      "\n",
      "Merged Dataset: GBaker/MedQA-USMLE-4-options-hf\n",
      "Split: test\n",
      "Contains 1323 rows.\n",
      "441 transformations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>n_questions</th>\n",
       "      <th>unique_brand_keywords</th>\n",
       "      <th>unique_generic_keywords</th>\n",
       "      <th>total_keyword_length</th>\n",
       "      <th>brand_keywords_count</th>\n",
       "      <th>generic_keywords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medmcqa</td>\n",
       "      <td>test</td>\n",
       "      <td>539</td>\n",
       "      <td>[]</td>\n",
       "      <td>[methylprednisolone, flecainide, terazosin, carboplatin, etoposide, rifampin, bran, chlorhexidine, ibutilide, ibuprofen, tizanidine, griseofulvin, quinine, lenalidomide, bupivacaine, metoclopramide, etonogestrel, propofol, ketorolac, naratriptan, exenatide, celiprolol, cimetidine, clomipramine, fomepizole, amiodarone, paracetamol, linezolid, methoxyflurane, dapsone, ciprofloxacin, tacrolimus, selegiline, mebendazole, zileuton, procainamide, podophyllin, metoprolol, etomidate, oxybutynin, topotecan, dipivefrine, suxamethonium, chlorambucil, phenoxybenzamine, carbamazepine, dicloxacillin, ofloxacin, trihexyphenidyl, sufentanil, cycloserine, dinoprostone, chloroquine, capecitabine, nitisinone, desflurane, benzocaine, gatifloxacin, simvastatin, metyrapone, prasugrel, physostigmine, miltefosine, ciclesonide, abatacept, risedronate, omalizumab, mesalazine, digoxin, piroxicam, sertraline, glutaraldehyde, tropicamide, ticlopidine, cisplatin, cetuximab, erythromycin, levamisole, olanzapine, sumatriptan, zafirlukast, sulfasalazine, omeprazole, triprolidine, ampicillin, levodopa, primidone, benazepril, daptomycin, foscarnet, fondaparinux, econazole, flumazenil, tamoxifen, moxifloxacin, cephalothin, ticagrelor, prednisolone, triptorelin, zonisamide, ...]</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBaker/MedQA-USMLE-4-options-hf</td>\n",
       "      <td>test</td>\n",
       "      <td>441</td>\n",
       "      <td>[]</td>\n",
       "      <td>[methylprednisolone, alendronate, epinephrine, aldesleukin, moxifloxacin, hydromorphone, carboplatin, ribavirin, oxycodone, nifedipine, etoposide, lansoprazole, rifampin, prednisolone, furosemide, calamine, atenolol, paroxetine, gabapentin, chlorhexidine, metronidazole, ibuprofen, enoxaparin, isoflurane, tolvaptan, scopolamine, glucagon, dantrolene, griseofulvin, methenamine, diphenhydramine, oxytocin, anakinra, liraglutide, chlorthalidone, dihydroergotamine, pramlintide, modafinil, isotretinoin, metoclopramide, miglitol, deferoxamine, fluorometholone, hydrochlorothiazide, lovastatin, estriol, pantoprazole, propofol, azithromycin, dexamethasone, ramelteon, methylphenidate, doxycycline, dobutamine, tolterodine, diethylstilbestrol, ketorolac, amlodipine, edta, temazepam, rasburicase, exenatide, atorvastatin, flucytosine, rosuvastatin, dextroamphetamine, cimetidine, clomipramine, isoniazid, vincristine, demeclocycline, fomepizole, amiodarone, naltrexone, lorazepam, fludrocortisone, atropine, naloxone, maraviroc, albendazole, dapsone, infliximab, ciprofloxacin, selegiline, sevoflurane, mebendazole, etanercept, carvedilol, erythropoietin, thalidomide, rivastigmine, lamivudine, indomethacin, baclofen, tetrahydrobiopterin, nitroprusside, fluoxetine, zileuton, triamterene, labetalol, ...]</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset split  n_questions unique_brand_keywords  \\\n",
       "0                          medmcqa  test          539                    []   \n",
       "1  GBaker/MedQA-USMLE-4-options-hf  test          441                    []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 unique_generic_keywords  \\\n",
       "0                                         [methylprednisolone, flecainide, terazosin, carboplatin, etoposide, rifampin, bran, chlorhexidine, ibutilide, ibuprofen, tizanidine, griseofulvin, quinine, lenalidomide, bupivacaine, metoclopramide, etonogestrel, propofol, ketorolac, naratriptan, exenatide, celiprolol, cimetidine, clomipramine, fomepizole, amiodarone, paracetamol, linezolid, methoxyflurane, dapsone, ciprofloxacin, tacrolimus, selegiline, mebendazole, zileuton, procainamide, podophyllin, metoprolol, etomidate, oxybutynin, topotecan, dipivefrine, suxamethonium, chlorambucil, phenoxybenzamine, carbamazepine, dicloxacillin, ofloxacin, trihexyphenidyl, sufentanil, cycloserine, dinoprostone, chloroquine, capecitabine, nitisinone, desflurane, benzocaine, gatifloxacin, simvastatin, metyrapone, prasugrel, physostigmine, miltefosine, ciclesonide, abatacept, risedronate, omalizumab, mesalazine, digoxin, piroxicam, sertraline, glutaraldehyde, tropicamide, ticlopidine, cisplatin, cetuximab, erythromycin, levamisole, olanzapine, sumatriptan, zafirlukast, sulfasalazine, omeprazole, triprolidine, ampicillin, levodopa, primidone, benazepril, daptomycin, foscarnet, fondaparinux, econazole, flumazenil, tamoxifen, moxifloxacin, cephalothin, ticagrelor, prednisolone, triptorelin, zonisamide, ...]   \n",
       "1  [methylprednisolone, alendronate, epinephrine, aldesleukin, moxifloxacin, hydromorphone, carboplatin, ribavirin, oxycodone, nifedipine, etoposide, lansoprazole, rifampin, prednisolone, furosemide, calamine, atenolol, paroxetine, gabapentin, chlorhexidine, metronidazole, ibuprofen, enoxaparin, isoflurane, tolvaptan, scopolamine, glucagon, dantrolene, griseofulvin, methenamine, diphenhydramine, oxytocin, anakinra, liraglutide, chlorthalidone, dihydroergotamine, pramlintide, modafinil, isotretinoin, metoclopramide, miglitol, deferoxamine, fluorometholone, hydrochlorothiazide, lovastatin, estriol, pantoprazole, propofol, azithromycin, dexamethasone, ramelteon, methylphenidate, doxycycline, dobutamine, tolterodine, diethylstilbestrol, ketorolac, amlodipine, edta, temazepam, rasburicase, exenatide, atorvastatin, flucytosine, rosuvastatin, dextroamphetamine, cimetidine, clomipramine, isoniazid, vincristine, demeclocycline, fomepizole, amiodarone, naltrexone, lorazepam, fludrocortisone, atropine, naloxone, maraviroc, albendazole, dapsone, infliximab, ciprofloxacin, selegiline, sevoflurane, mebendazole, etanercept, carvedilol, erythropoietin, thalidomide, rivastigmine, lamivudine, indomethacin, baclofen, tetrahydrobiopterin, nitroprusside, fluoxetine, zileuton, triamterene, labetalol, ...]   \n",
       "\n",
       "   total_keyword_length  brand_keywords_count  generic_keywords_count  \n",
       "0                  1002                     0                    1000  \n",
       "1                   950                     0                     947  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_brand_generic_maps(brand_to_generic_path, generic_to_brand_path):\n",
    "    brand_to_generic_df = pd.read_csv(brand_to_generic_path)\n",
    "    generic_to_brand_df = pd.read_csv(generic_to_brand_path)\n",
    "\n",
    "    return brand_to_generic_df, generic_to_brand_df\n",
    "\n",
    "\n",
    "def count_keywords(merged_datasets, split, brand_keywords, generic_keywords):\n",
    "    results = []\n",
    "    unique_brand_keywords_per_dataset = {}\n",
    "    unique_generic_keywords_per_dataset = {}\n",
    "\n",
    "    for dataset_name, df in merged_datasets.items():\n",
    "        if \"found_keywords\" in df.columns:\n",
    "            # Flatten the list of keywords\n",
    "            all_keywords = [\n",
    "                keyword\n",
    "                for sublist in df[\"found_keywords\"].dropna()\n",
    "                for keyword in sublist\n",
    "            ]\n",
    "            unique_keywords = set(all_keywords)\n",
    "\n",
    "            # Separate brand and generic keywords\n",
    "            unique_brand_keywords = unique_keywords.intersection(brand_keywords)\n",
    "            unique_generic_keywords = unique_keywords.intersection(generic_keywords)\n",
    "\n",
    "            # Store unique keywords for later use\n",
    "            unique_brand_keywords_per_dataset[dataset_name] = unique_brand_keywords\n",
    "            unique_generic_keywords_per_dataset[dataset_name] = unique_generic_keywords\n",
    "\n",
    "            # Count total number of words (keywords)\n",
    "            total_keyword_length = len(all_keywords)\n",
    "\n",
    "            # Count brand and generic keywords\n",
    "            brand_keyword_count = sum(\n",
    "                1 for keyword in all_keywords if keyword in brand_keywords\n",
    "            )\n",
    "            generic_keyword_count = sum(\n",
    "                1 for keyword in all_keywords if keyword in generic_keywords\n",
    "            )\n",
    "\n",
    "            # divide by 3 to get the number of questions\n",
    "            total_keyword_length = total_keyword_length // 3\n",
    "            brand_keyword_count = brand_keyword_count // 3\n",
    "            generic_keyword_count = generic_keyword_count // 3\n",
    "\n",
    "            # get n questions\n",
    "            n = len(df) // 3\n",
    "\n",
    "            # Collect the results\n",
    "            results.append(\n",
    "                {\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"split\": split,\n",
    "                    \"n_questions\": n,\n",
    "                    \"unique_brand_keywords\": list(unique_brand_keywords),\n",
    "                    \"unique_generic_keywords\": list(unique_generic_keywords),\n",
    "                    \"total_keyword_length\": total_keyword_length,\n",
    "                    \"brand_keywords_count\": brand_keyword_count,\n",
    "                    \"generic_keywords_count\": generic_keyword_count,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No 'found_keywords' column in {dataset_name}\")\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(results),\n",
    "        unique_brand_keywords_per_dataset,\n",
    "        unique_generic_keywords_per_dataset,\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_and_save_mappings(\n",
    "    dataset_name,\n",
    "    unique_brand_keywords,\n",
    "    unique_generic_keywords,\n",
    "    brand_to_generic_df,\n",
    "    generic_to_brand_df,\n",
    "):\n",
    "    filtered_brand_to_generic = brand_to_generic_df[\n",
    "        brand_to_generic_df[\"brand\"].isin(unique_brand_keywords)\n",
    "    ]\n",
    "    filtered_generic_to_brand = generic_to_brand_df[\n",
    "        generic_to_brand_df[\"generic\"].isin(unique_generic_keywords)\n",
    "    ]\n",
    "\n",
    "    # clean dataset name\n",
    "    dataset_name = dataset_name.replace(\"/\", \"_\")\n",
    "\n",
    "    filtered_brand_to_generic.to_csv(\n",
    "        f\"../RxNorm_eval/filtered_brand_to_generic_{dataset_name}.csv\", index=False\n",
    "    )\n",
    "    filtered_generic_to_brand.to_csv(\n",
    "        f\"../RxNorm_eval/filtered_generic_to_brand_{dataset_name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "\n",
    "# Load brand and generic keyword maps\n",
    "brand_to_generic_path = \"../RxNorm_eval/filtered_keywords.csv\"\n",
    "generic_to_brand_path = \"../RxNorm_eval/filtered_keywords.csv\"\n",
    "brand_to_generic_df, generic_to_brand_df = load_brand_generic_maps(\n",
    "    brand_to_generic_path, generic_to_brand_path\n",
    ")\n",
    "\n",
    "# Assuming merge_all_datasets function is already defined\n",
    "merged_datasets = merge_all_datasets(pre_filtered_df_dir, split)\n",
    "\n",
    "# Load brand and generic keywords\n",
    "brand_keywords = set(brand_to_generic_df[\"brand\"])\n",
    "generic_keywords = set(generic_to_brand_df[\"generic\"])\n",
    "\n",
    "# Count keywords and get the result as a DataFrame\n",
    "keywords_df, unique_brand_keywords_per_dataset, unique_generic_keywords_per_dataset = (\n",
    "    count_keywords(merged_datasets, split, brand_keywords, generic_keywords)\n",
    ")\n",
    "\n",
    "# Save the keywords_df\n",
    "keywords_df.to_csv(f\"../RxNorm_eval/keywords_count_{split}.csv\", index=False)\n",
    "\n",
    "# Filter and save brand_to_generic and generic_to_brand mappings for each dataset\n",
    "for dataset_name in unique_brand_keywords_per_dataset:\n",
    "    unique_brand_keywords = unique_brand_keywords_per_dataset[dataset_name]\n",
    "    unique_generic_keywords = unique_generic_keywords_per_dataset[dataset_name]\n",
    "    filter_and_save_mappings(\n",
    "        dataset_name,\n",
    "        unique_brand_keywords,\n",
    "        unique_generic_keywords,\n",
    "        brand_to_generic_df,\n",
    "        generic_to_brand_df,\n",
    "    )\n",
    "\n",
    "# Display the result\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['methylprednisolone', 'alendronate', 'epinephrine', 'aldesleukin', 'moxifloxacin', 'hydromorphone', 'carboplatin', 'ribavirin', 'oxycodone', 'nifedipine', 'etoposide', 'lansoprazole', 'rifampin', 'prednisolone', 'furosemide', 'calamine', 'atenolol', 'paroxetine', 'gabapentin', 'chlorhexidine', 'metronidazole', 'ibuprofen', 'enoxaparin', 'isoflurane', 'tolvaptan', 'scopolamine', 'glucagon', 'dantrolene', 'griseofulvin', 'methenamine', 'diphenhydramine', 'oxytocin', 'anakinra', 'liraglutide', 'chlorthalidone', 'dihydroergotamine', 'pramlintide', 'modafinil', 'isotretinoin', 'metoclopramide', 'miglitol', 'deferoxamine', 'fluorometholone', 'hydrochlorothiazide', 'lovastatin', 'estriol', 'pantoprazole', 'propofol', 'azithromycin', 'dexamethasone', 'ramelteon', 'methylphenidate', 'doxycycline', 'dobutamine', 'tolterodine', 'diethylstilbestrol', 'ketorolac', 'amlodipine', 'edta', 'temazepam', 'rasburicase', 'exenatide', 'atorvastatin', 'flucytosine', 'rosuvastatin', 'dextroamphetamine', 'cimetidine', 'clomipramine', 'isoniazid', 'vincristine', 'demeclocycline', 'fomepizole', 'amiodarone', 'naltrexone', 'lorazepam', 'fludrocortisone', 'atropine', 'naloxone', 'maraviroc', 'albendazole', 'dapsone', 'infliximab', 'ciprofloxacin', 'selegiline', 'sevoflurane', 'mebendazole', 'etanercept', 'carvedilol', 'erythropoietin', 'thalidomide', 'rivastigmine', 'lamivudine', 'indomethacin', 'baclofen', 'tetrahydrobiopterin', 'nitroprusside', 'fluoxetine', 'zileuton', 'triamterene', 'labetalol', 'clarithromycin', 'mesna', 'lamotrigine', 'oxaliplatin', 'tiotropium', 'quetiapine', 'emtricitabine', 'cefotaxime', 'clozapine', 'fluphenazine', 'metoprolol', 'ethinylestradiol', 'memantine', 'methadone', 'chlordiazepoxide', 'levofloxacin', 'verapamil', 'cilostazol', 'zidovudine', 'etomidate', 'cyclophosphamide', 'oxybutynin', 'valproate', 'fluvastatin', 'voriconazole', 'sildenafil', 'empagliflozin', 'simeprevir', 'paromomycin', 'theophylline', 'azathioprine', 'nitroglycerin', 'imatinib', 'chlorpromazine', 'phenytoin', 'nortriptyline', 'romiplostim', 'phenoxybenzamine', 'trimethoprim', 'diltiazem', 'carbamazepine', 'cyproheptadine', 'fluorouracil', 'phentolamine', 'mepolizumab', 'dicloxacillin', 'trihexyphenidyl', 'sitagliptin', 'chloroquine', 'riluzole', 'loperamide', 'oseltamivir', 'desflurane', 'mannitol', 'methotrexate', 'ergocalciferol', 'oxybate', 'pioglitazone', 'ruxolitinib', 'itraconazole', 'apixaban', 'losartan', 'simvastatin', 'imipramine', 'phenylephrine', 'metyrapone', 'doxorubicin', 'loratadine', 'ranitidine', 'allopurinol', 'trazodone', 'darunavir', 'physostigmine', 'ketoprofen', 'cromolyn', 'oxymetazoline', 'amantadine', 'ketamine', 'fexofenadine', 'midodrine', 'esmolol', 'galantamine', 'mifepristone', 'tetracycline', 'diclofenac', 'propranolol', 'hydralazine', 'cyclosporine', 'clopidogrel', 'moxonidine', 'clonidine', 'chloramphenicol', 'ethambutol', 'dasatinib', 'vasopressin', 'captopril', 'ertapenem', 'gentamicin', 'thyroxine', 'amitriptyline', 'atracurium', 'digoxin', 'fluconazole', 'ganciclovir', 'prazosin', 'alprazolam', 'ritonavir', 'warfarin', 'triamcinolone', 'sertraline', 'bethanechol', 'neostigmine', 'meloxicam', 'rifaximin', 'dolutegravir', 'nitrofurantoin', 'telmisartan', 'cefpodoxime', 'aliskiren', 'vancomycin', 'febuxostat', 'valsartan', 'povidone-iodine', 'ipratropium', 'salmeterol', 'pramipexole', 'spironolactone', 'mefloquine', 'methysergide', 'cisplatin', 'ceftriaxone', 'bromocriptine', 'diazepam', 'anastrozole', 'calcitriol', 'goserelin', 'eplerenone', 'erythromycin', 'rituximab', 'hydroxychloroquine', 'naproxen', 'glipizide', 'nesiritide', 'duloxetine', 'rivaroxaban', 'salbutamol', 'disulfiram', 'entecavir', 'streptokinase', 'olanzapine', 'morphine', 'fenofibrate', 'prednisone', 'sumatriptan', 'midazolam', 'montelukast', 'docusate', 'acetazolamide', 'bisoprolol', 'ramipril', 'colchicine', 'povidone', 'omeprazole', 'octreotide', 'bacitracin', 'benztropine', 'sofosbuvir', 'sevelamer', 'enalapril', 'triazolam', 'ivermectin', 'ampicillin', 'leucovorin', 'primidone', 'escitalopram', 'efavirenz', 'phenobarbital', 'donepezil', 'cefotetan', 'raloxifene', 'fondaparinux', 'pravastatin', 'succimer', 'metformin', 'lidocaine', 'lactulose', 'colesevelam', 'phenelzine', 'bupropion', 'lisinopril', 'cephalexin', 'fludarabine', 'tamoxifen', 'citalopram', 'ketotifen', 'alteplase', 'teriparatide', 'tramadol', 'terbutaline', 'cladribine', 'misoprostol', 'isosorbide']\n"
     ]
    }
   ],
   "source": [
    "print(keywords_df[\"unique_generic_keywords\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load g2b medmcqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_ids that we want to drop for unique datasets\n",
    "## dictionary of dataset and local_ids to drop\n",
    "drop_local_ids = {\n",
    "    \"augtoma/usmle_step_1\": [],\n",
    "    \"augtoma/usmle_step_2\": [],\n",
    "    \"augtoma/usmle_step_3\": [],\n",
    "    \"bigbio/pubmed_qa\": [],\n",
    "    \"GBaker/MedQA-USMLE-4-options-hf\": [],\n",
    "    \"medmcqa\": [],\n",
    "    \"hails/mmlu_no_train/anatomy\": [],\n",
    "    \"hails/mmlu_no_train/clinical_knowledge\": [],\n",
    "    \"hails/mmlu_no_train/college_biology\": [],\n",
    "    \"hails/mmlu_no_train/college_medicine\": [],\n",
    "    \"hails/mmlu_no_train/medical_genetics\": [],\n",
    "    \"hails/mmlu_no_train/professional_medicine\": [],\n",
    "}\n",
    "\n",
    "# drop local_ids\n",
    "for dataset_name, local_ids in drop_local_ids.items():\n",
    "    if dataset_name in merged_datasets:\n",
    "        merged_datasets[dataset_name] = merged_datasets[dataset_name][\n",
    "            ~merged_datasets[dataset_name][\"local_id\"].isin(local_ids)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out dataset: medmcqa_original_filtered to ../datasets/medmcqa/test\n",
      "Writing out dataset: medmcqa_brand_to_generic_filtered to ../datasets/medmcqa/test\n",
      "Writing out dataset: medmcqa_generic_to_brand_filtered to ../datasets/medmcqa/test\n",
      "Writing out dataset: bigbio/pubmed_qa_original_filtered to ../datasets/bigbio_pubmed_qa/test\n",
      "Writing out dataset: bigbio/pubmed_qa_brand_to_generic_filtered to ../datasets/bigbio_pubmed_qa/test\n",
      "Writing out dataset: bigbio/pubmed_qa_generic_to_brand_filtered to ../datasets/bigbio_pubmed_qa/test\n",
      "Writing out dataset: GBaker/MedQA-USMLE-4-options-hf_original_filtered to ../datasets/GBaker_MedQA-USMLE-4-options-hf/test\n",
      "Writing out dataset: GBaker/MedQA-USMLE-4-options-hf_brand_to_generic_filtered to ../datasets/GBaker_MedQA-USMLE-4-options-hf/test\n",
      "Writing out dataset: GBaker/MedQA-USMLE-4-options-hf_generic_to_brand_filtered to ../datasets/GBaker_MedQA-USMLE-4-options-hf/test\n",
      "Writing out dataset: augtoma/usmle_step_1_original_filtered to ../datasets/augtoma_usmle_step_1/test\n",
      "Writing out dataset: augtoma/usmle_step_1_brand_to_generic_filtered to ../datasets/augtoma_usmle_step_1/test\n",
      "Writing out dataset: augtoma/usmle_step_1_generic_to_brand_filtered to ../datasets/augtoma_usmle_step_1/test\n",
      "Writing out dataset: augtoma/usmle_step_2_original_filtered to ../datasets/augtoma_usmle_step_2/test\n",
      "Writing out dataset: augtoma/usmle_step_2_brand_to_generic_filtered to ../datasets/augtoma_usmle_step_2/test\n",
      "Writing out dataset: augtoma/usmle_step_2_generic_to_brand_filtered to ../datasets/augtoma_usmle_step_2/test\n",
      "Writing out dataset: augtoma/usmle_step_3_original_filtered to ../datasets/augtoma_usmle_step_3/test\n",
      "Writing out dataset: augtoma/usmle_step_3_brand_to_generic_filtered to ../datasets/augtoma_usmle_step_3/test\n",
      "Writing out dataset: augtoma/usmle_step_3_generic_to_brand_filtered to ../datasets/augtoma_usmle_step_3/test\n",
      "Writing out dataset: hails/mmlu_no_train/anatomy_original_filtered to ../datasets/hails_mmlu_no_train_anatomy/test\n",
      "Writing out dataset: hails/mmlu_no_train/anatomy_brand_to_generic_filtered to ../datasets/hails_mmlu_no_train_anatomy/test\n",
      "Writing out dataset: hails/mmlu_no_train/anatomy_generic_to_brand_filtered to ../datasets/hails_mmlu_no_train_anatomy/test\n",
      "Writing out dataset: hails/mmlu_no_train/clinical_knowledge_original_filtered to ../datasets/hails_mmlu_no_train_clinical_knowledge/test\n",
      "Writing out dataset: hails/mmlu_no_train/clinical_knowledge_brand_to_generic_filtered to ../datasets/hails_mmlu_no_train_clinical_knowledge/test\n",
      "Writing out dataset: hails/mmlu_no_train/clinical_knowledge_generic_to_brand_filtered to ../datasets/hails_mmlu_no_train_clinical_knowledge/test\n",
      "Writing out dataset: hails/mmlu_no_train/professional_medicine_original_filtered to ../datasets/hails_mmlu_no_train_professional_medicine/test\n",
      "Writing out dataset: hails/mmlu_no_train/professional_medicine_brand_to_generic_filtered to ../datasets/hails_mmlu_no_train_professional_medicine/test\n",
      "Writing out dataset: hails/mmlu_no_train/professional_medicine_generic_to_brand_filtered to ../datasets/hails_mmlu_no_train_professional_medicine/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
      "/var/folders/06/cy8f7k7d5pb31b4b4fpr97z80000gn/T/ipykernel_41932/3434853051.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Now write out the datasets back to independent files per transformation\n",
    "for dataset_name, dataset in merged_datasets.items():\n",
    "    for transformation in dataset[\"transformation_type\"].unique():\n",
    "        dataset_filtered = dataset[dataset[\"transformation_type\"] == transformation]\n",
    "        if len(dataset_filtered) == 0:\n",
    "            print(\n",
    "                f\"Skipping dataset {dataset_name}_{transformation} as it has no rows.\"\n",
    "            )\n",
    "            continue\n",
    "        dataset_filtered.drop(columns=[\"transformation_type\"], inplace=True)\n",
    "        dataset_filtered.reset_index(drop=True, inplace=True)\n",
    "        dataset_filtered_path = os.path.join(\n",
    "            output_dir,\n",
    "            f\"{dataset_name.replace('/', '_')}\",\n",
    "            f\"{split}\",\n",
    "            f\"{dataset_name.replace('/', '_')}_{transformation}\",\n",
    "            f\"{split}.parquet\",\n",
    "        )\n",
    "        if not os.path.exists(os.path.dirname(dataset_filtered_path)):\n",
    "            os.makedirs(os.path.dirname(dataset_filtered_path))\n",
    "        dataset_filtered.to_parquet(\n",
    "            dataset_filtered_path,\n",
    "        )\n",
    "        print(\n",
    "            f\"Writing out dataset: {dataset_name}_{transformation} to {output_dir}/{dataset_name.replace('/', '_')}/{split}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39_117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
